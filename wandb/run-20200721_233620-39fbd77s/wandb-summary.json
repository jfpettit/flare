{"_runtime": 252.0414261817932, "KL": 0.006648109760135412, "Entropy": 0.6879680752754211, "grad_2.0_norm_ac.value_f.layers.2.bias": 21.004, "ValueLoss": 2019.4610595703125, "grad_2.0_norm_ac.value_f.layers.1.weight": 137.739, "grad_2.0_norm_ac.policy.net.layers.0.weight": 0.0, "grad_2.0_norm_ac.value_f.layers.2.weight": 143.147, "MaxEpReturn": -265.73860110713485, "grad_2.0_norm_ac.value_f.layers.0.weight": 58.922, "grad_2.0_norm_total": 209.984, "MeanEpReturn": -599.1361161150323, "grad_2.0_norm_ac.policy.net.layers.1.bias": 0.0, "grad_2.0_norm_ac.value_f.layers.0.bias": 12.905, "TimesEarlyStopped": 0, "grad_2.0_norm_ac.value_f.layers.1.bias": 23.463, "_timestamp": 1595400027.3893461, "global_step": 37, "MeanEpLength": 1000.0, "AvgEarlyStopStep": 0, "DeltaPolLoss": -0.017113937065005302, "grad_2.0_norm_ac.policy.logstd": 0.0, "grad_2.0_norm_ac.policy.net.layers.2.bias": 0.0, "grad_2.0_norm_ac.policy.net.layers.2.weight": 0.0, "epoch": 37, "MinEpReturn": -1368.9121420751737, "DeltaValLoss": -386.498779296875, "grad_2.0_norm_ac.policy.net.layers.0.bias": 0.0, "grad_2.0_norm_ac.policy.net.layers.1.weight": 0.0, "_step": 37, "PolicyLoss": -2.4318694613612024e-08}
